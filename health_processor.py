#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¥ GitHub Actionsç”¨ä½“çµ„æˆç®¡ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ v1.0
Railway â†’ GitHubç§»æ¤ç‰ˆï¼ˆå®Œå…¨ç„¡æ–™å¯¾å¿œï¼‰

æ©Ÿèƒ½:
- HAEãƒ‡ãƒ¼ã‚¿è‡ªå‹•å‡¦ç†ï¼ˆJSON â†’ CSVçµ±åˆï¼‰
- å¥åº·åˆ†æãƒ»LINEé€šçŸ¥
- GitHub Actionsç’°å¢ƒæœ€é©åŒ–
- ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ï¼ˆãƒªãƒã‚¸ãƒˆãƒªä¿å­˜ï¼‰

ç’°å¢ƒå¤‰æ•°ï¼ˆGitHub Secretsï¼‰:
- LINE_BOT_CHANNEL_ACCESS_TOKEN
- LINE_USER_ID  
- OURA_ACCESS_TOKEN
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import requests
import traceback
import logging
from typing import Dict, List, Any, Optional

# ===== ãƒ­ã‚°è¨­å®š =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# ===== GitHub Actionsç’°å¢ƒå¯¾å¿œ =====
class GitHubEnvironment:
    """GitHub Actionsç’°å¢ƒæƒ…å ±"""
    
    def __init__(self):
        self.workspace = os.environ.get('GITHUB_WORKSPACE', '.')
        self.is_github_actions = bool(os.environ.get('GITHUB_ACTIONS'))
        self.event_name = os.environ.get('GITHUB_EVENT_NAME', 'unknown')
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.base_dir = Path(self.workspace)
        self.data_dir = self.base_dir / 'health_api_data'
        self.reports_dir = self.base_dir / 'reports'
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.data_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸŒ GitHub Actions: {'âœ…æœ‰åŠ¹' if self.is_github_actions else 'âŒãƒ­ãƒ¼ã‚«ãƒ«'}")
        logger.info(f"ğŸ“ ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹: {self.workspace}")
        logger.info(f"ğŸ”„ ã‚¤ãƒ™ãƒ³ãƒˆ: {self.event_name}")

# ===== HAEãƒ‡ãƒ¼ã‚¿å¤‰æ›æ©Ÿèƒ½ =====
class HAEDataConverter:
    """HAEãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã«å¤‰æ›ï¼ˆç§»æ¤ç‰ˆï¼‰"""
    
    METRIC_MAPPING = {
        'weight_body_mass': 'ä½“é‡_kg',
        'lean_body_mass': 'ç­‹è‚‰é‡_kg', 
        'body_fat_percentage': 'ä½“è„‚è‚ªç‡',
        'dietary_energy': 'æ‘‚å–ã‚«ãƒ­ãƒªãƒ¼_kcal',
        'basal_energy_burned': 'åŸºç¤ä»£è¬_kcal',
        'active_energy': 'æ´»å‹•ã‚«ãƒ­ãƒªãƒ¼_kcal',
        'step_count': 'æ­©æ•°',
        'sleep_analysis': 'ç¡çœ æ™‚é–“_hours',
        'protein': 'ã‚¿ãƒ³ãƒ‘ã‚¯è³ª_g',
        'carbohydrates': 'ç‚­æ°´åŒ–ç‰©_g',
        'dietary_sugar': 'ç³–è³ª_g',
        'fiber': 'é£Ÿç‰©ç¹Šç¶­_g',
        'total_fat': 'è„‚è³ª_g'
    }
    
    def convert_hae_to_daily_row(self, hae_data: Dict) -> Dict:
        """HAE JSONã‚’æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿è¡Œã«å¤‰æ›"""
        try:
            logger.info("ğŸ”„ HAEãƒ‡ãƒ¼ã‚¿å¤‰æ›é–‹å§‹")
            metrics = hae_data.get('data', {}).get('metrics', [])
            logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ•°: {len(metrics)}")
            
            # åŸºæœ¬è¡Œãƒ‡ãƒ¼ã‚¿ï¼ˆPhase1ä¿®æ­£ç‰ˆï¼‰
            daily_row = {
                'date': datetime.now().strftime('%Y-%m-%d'),
                'ä½“é‡_kg': None,
                'ç­‹è‚‰é‡_kg': None,
                'ä½“è„‚è‚ªé‡_kg': None,
                'ä½“è„‚è‚ªç‡': None,
                'ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal': None,
                'æ‘‚å–ã‚«ãƒ­ãƒªãƒ¼_kcal': None,
                'æ¶ˆè²»ã‚«ãƒ­ãƒªãƒ¼_kcal': None,
                'åŸºç¤ä»£è¬_kcal': None,
                'æ´»å‹•ã‚«ãƒ­ãƒªãƒ¼_kcal': None,
                'æ­©æ•°': None,
                'ç¡çœ æ™‚é–“_hours': None,
                'ä½“è¡¨æ¸©åº¦_celsius': None,
                'ä½“è¡¨æ¸©å¤‰åŒ–_celsius': None,
                'ä½“è¡¨æ¸©åå·®_celsius': None,
                'ä½“è¡¨æ¸©ãƒˆãƒ¬ãƒ³ãƒ‰_celsius': None,
                'ã‚¿ãƒ³ãƒ‘ã‚¯è³ª_g': None,
                'ç³–è³ª_g': None,
                'ç‚­æ°´åŒ–ç‰©_g': None,  # Phase1ä¿®æ­£: è¿½åŠ 
                'é£Ÿç‰©ç¹Šç¶­_g': None,
                'è„‚è³ª_g': None,
                'oura_total_calories': None,
                'oura_estimated_basal': None,
                'total_calories_updated': None,
                'calculation_method': 'GITHUB_ACTIONS'
            }
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å¤‰æ›ï¼ˆPhase1ä¿®æ­£å¯¾å¿œï¼‰
            converted_count = 0
            for metric in metrics:
                name = metric.get('name', '')
                if name in self.METRIC_MAPPING:
                    csv_column = self.METRIC_MAPPING[name]
                    data_points = metric.get('data', [])
                    
                    if data_points:
                        latest_point = data_points[-1]
                        
                        # ã€Phase1ä¿®æ­£ã€‘sleep_analysiså°‚ç”¨å‡¦ç†
                        if name == 'sleep_analysis':
                            daily_row[csv_column] = latest_point.get('totalSleep')
                        else:
                            daily_row[csv_column] = latest_point.get('qty')
                        
                        converted_count += 1
                        logger.info(f"âœ… {name} â†’ {csv_column}: {daily_row[csv_column]}")
            
            logger.info(f"ğŸ¯ å¤‰æ›å®Œäº†: {converted_count}å€‹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
            
            # è¨ˆç®—å‡¦ç†
            self._calculate_derived_values(daily_row)
            
            return daily_row
            
        except Exception as e:
            logger.error(f"âŒ HAEãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _calculate_derived_values(self, daily_row: Dict):
        """æ´¾ç”Ÿå€¤è¨ˆç®—"""
        # ä½“è„‚è‚ªé‡è¨ˆç®—
        if daily_row['ä½“é‡_kg'] and daily_row['ä½“è„‚è‚ªç‡']:
            daily_row['ä½“è„‚è‚ªé‡_kg'] = daily_row['ä½“é‡_kg'] * (daily_row['ä½“è„‚è‚ªç‡'] / 100)
            logger.info(f"ğŸ’¡ ä½“è„‚è‚ªé‡è¨ˆç®—: {daily_row['ä½“è„‚è‚ªé‡_kg']:.2f}kg")
        
        # ã‚«ãƒ­ãƒªãƒ¼åæ”¯è¨ˆç®—
        intake = daily_row['æ‘‚å–ã‚«ãƒ­ãƒªãƒ¼_kcal'] or 0
        basal = daily_row['åŸºç¤ä»£è¬_kcal'] or 0
        active = daily_row['æ´»å‹•ã‚«ãƒ­ãƒªãƒ¼_kcal'] or 0
        
        if intake and (basal or active):
            daily_row['æ¶ˆè²»ã‚«ãƒ­ãƒªãƒ¼_kcal'] = basal + active
            daily_row['ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal'] = intake - (basal + active)
            logger.info(f"ğŸ”¥ ã‚«ãƒ­ãƒªãƒ¼åæ”¯: {daily_row['ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal']}kcal")

# ===== CSVçµ±åˆæ©Ÿèƒ½ =====
class CSVDataIntegrator:
    """HAEãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜CSVã«çµ±åˆï¼ˆGitHubç‰ˆï¼‰"""
    
    def __init__(self, reports_dir: Path):
        self.reports_dir = reports_dir
        self.daily_csv = self.reports_dir / "daily_health_data.csv"
        self.ma_csv = self.reports_dir / "health_data_with_ma.csv"
        self.index_csv = self.reports_dir / "health_data_index.csv"
        logger.info(f"ğŸ“Š CSVçµ±åˆæ©Ÿèƒ½åˆæœŸåŒ–: {self.reports_dir}")
    
    def integrate_daily_data(self, daily_row: Dict) -> bool:
        """æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«çµ±åˆ"""
        try:
            logger.info("ğŸ”„ CSVçµ±åˆé–‹å§‹")
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if self.daily_csv.exists():
                df = pd.read_csv(self.daily_csv, encoding='utf-8-sig')
                logger.info(f"ğŸ“– æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}è¡Œ")
            else:
                df = pd.DataFrame()
                logger.info("ğŸ“ æ–°è¦ãƒ‡ãƒ¼ã‚¿ä½œæˆ")
            
            # æ–°ãƒ‡ãƒ¼ã‚¿è¿½åŠ ï¼ˆåŒä¸€æ—¥ä»˜ã¯ä¸Šæ›¸ãï¼‰
            new_df = pd.DataFrame([daily_row])
            if not df.empty:
                df = df[df['date'] != daily_row['date']]
                df = pd.concat([df, new_df], ignore_index=True)
            else:
                df = new_df
            
            # æ—¥ä»˜é †ã‚½ãƒ¼ãƒˆ
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
            df['date'] = df['date'].dt.strftime('%Y-%m-%d')
            
            # UTF-8 BOMä»˜ãã§ä¿å­˜ï¼ˆWindows Excelå¯¾å¿œï¼‰
            df.to_csv(self.daily_csv, index=False, encoding='utf-8-sig')
            logger.info(f"ğŸ’¾ æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {len(df)}è¡Œ")
            
            # ç§»å‹•å¹³å‡å†è¨ˆç®—
            self._recalculate_moving_averages(df)
            
            logger.info("âœ… CSVçµ±åˆå®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ CSVçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return False
    
    def _recalculate_moving_averages(self, df: pd.DataFrame):
        """ç§»å‹•å¹³å‡å†è¨ˆç®—"""
        try:
            logger.info("ğŸ”„ ç§»å‹•å¹³å‡è¨ˆç®—é–‹å§‹")
            
            # æ•°å€¤ã‚«ãƒ©ãƒ ã®ç§»å‹•å¹³å‡è¨ˆç®—
            numeric_columns = ['ä½“é‡_kg', 'ç­‹è‚‰é‡_kg', 'ä½“è„‚è‚ªé‡_kg', 'ä½“è„‚è‚ªç‡', 
                             'ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal', 'æ‘‚å–ã‚«ãƒ­ãƒªãƒ¼_kcal', 'æ¶ˆè²»ã‚«ãƒ­ãƒªãƒ¼_kcal',
                             'åŸºç¤ä»£è¬_kcal', 'æ´»å‹•ã‚«ãƒ­ãƒªãƒ¼_kcal', 'æ­©æ•°', 'ç¡çœ æ™‚é–“_hours']
            
            calculated_count = 0
            for col in numeric_columns:
                if col in df.columns:
                    df[f'{col}_ma7'] = df[col].rolling(window=7, min_periods=1).mean()
                    df[f'{col}_ma14'] = df[col].rolling(window=14, min_periods=1).mean()
                    df[f'{col}_ma28'] = df[col].rolling(window=28, min_periods=1).mean()
                    calculated_count += 1
            
            # ç§»å‹•å¹³å‡ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            df.to_csv(self.ma_csv, index=False, encoding='utf-8-sig')
            df.to_csv(self.index_csv, index=False, encoding='utf-8-sig')
            
            logger.info(f"âœ… ç§»å‹•å¹³å‡è¨ˆç®—å®Œäº†: {calculated_count}ã‚«ãƒ©ãƒ å‡¦ç†")
            
        except Exception as e:
            logger.error(f"âŒ ç§»å‹•å¹³å‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

# ===== å¥åº·åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ =====
class HealthAnalyticsEngine:
    """å¥åº·æŒ‡æ¨™åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆGitHubç‰ˆï¼‰"""
    
    def __init__(self, reports_dir: Path):
        self.reports_dir = reports_dir
        self.target_body_fat_rate = 12.0
        logger.info(f"ğŸ§  å¥åº·åˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ï¼ˆç›®æ¨™ä½“è„‚è‚ªç‡: {self.target_body_fat_rate}%ï¼‰")
    
    def analyze_health_data(self) -> Optional[Dict]:
        """å¥åº·ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿè¡Œ"""
        try:
            logger.info("ğŸ”„ å¥åº·åˆ†æé–‹å§‹")
            
            ma_file = self.reports_dir / "health_data_with_ma.csv"
            if not ma_file.exists():
                logger.error("âŒ ç§»å‹•å¹³å‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            df = pd.read_csv(ma_file, encoding='utf-8-sig')
            if df.empty:
                logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return None
            
            logger.info(f"ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ")
            
            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
            latest = df.iloc[-1]
            logger.info(f"ğŸ“… æœ€æ–°ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜: {latest.get('date')}")
            
            # åˆ†æçµæœä½œæˆ
            report = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'system': 'GitHub Actions v1.0',
                'current_body_fat_rate': latest.get('ä½“è„‚è‚ªç‡'),
                'target_body_fat_rate': self.target_body_fat_rate,
                'body_fat_progress': self._calculate_progress(df),
                'body_composition': {
                    'weight': latest.get('ä½“é‡_kg'),
                    'muscle_mass': latest.get('ç­‹è‚‰é‡_kg'),
                    'body_fat_mass': latest.get('ä½“è„‚è‚ªé‡_kg')
                },
                'calorie_balance': {
                    'current': latest.get('ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal'),
                    '7day_avg': latest.get('ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal_ma7'),
                    '14day_avg': latest.get('ã‚«ãƒ­ãƒªãƒ¼åæ”¯_kcal_ma14')
                }
            }
            
            # åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            report_file = self.reports_dir / f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file.name}")
            logger.info(f"ğŸ¯ ç¾åœ¨ä½“è„‚è‚ªç‡: {report['current_body_fat_rate']}%")
            logger.info("âœ… å¥åº·åˆ†æå®Œäº†")
            return report
            
        except Exception as e:
            logger.error(f"âŒ å¥åº·åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _calculate_progress(self, df: pd.DataFrame) -> Dict:
        """é€²æ—è¨ˆç®—"""
        latest = df.iloc[-1]
        current_bf = latest.get('ä½“è„‚è‚ªç‡', 0)
        
        progress = {}
        for days in [7, 14, 28]:
            if len(df) >= days + 1:
                past_bf = df.iloc[-(days + 1)].get('ä½“è„‚è‚ªç‡', current_bf)
                progress[f'{days}day_change'] = current_bf - past_bf
            else:
                progress[f'{days}day_change'] = 0
        
        return progress

# ===== LINEé€šçŸ¥æ©Ÿèƒ½ =====
class LineBotNotifier:
    """LINE Bot APIé€šçŸ¥ï¼ˆGitHubç‰ˆï¼‰"""
    
    def __init__(self):
        self.token = os.environ.get('LINE_BOT_CHANNEL_ACCESS_TOKEN')
        self.user_id = os.environ.get('LINE_USER_ID')
        self.api_url = "https://api.line.me/v2/bot/message/push"
        logger.info(f"ğŸ“± LINEé€šçŸ¥æ©Ÿèƒ½åˆæœŸåŒ–ï¼ˆè¨­å®š: {'âœ…å®Œäº†' if self.token and self.user_id else 'âŒä¸å®Œå…¨'}ï¼‰")
    
    def send_health_report(self, report: Dict) -> bool:
        """å¥åº·ãƒ¬ãƒãƒ¼ãƒˆã‚’LINEé€ä¿¡"""
        if not self.token or not self.user_id:
            logger.error("âŒ LINEè¨­å®šãŒä¸å®Œå…¨ã§ã™")
            return False
        
        try:
            logger.info("ğŸ”„ LINEé€šçŸ¥é€ä¿¡é–‹å§‹")
            
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
            message = self._format_health_message(report)
            logger.info(f"ğŸ“ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆå®Œäº†ï¼ˆ{len(message)}æ–‡å­—ï¼‰")
            
            headers = {
                'Authorization': f'Bearer {self.token}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'to': self.user_id,
                'messages': [{'type': 'text', 'text': message}]
            }
            
            logger.info("ğŸš€ LINE APIå‘¼ã³å‡ºã—å®Ÿè¡Œ")
            response = requests.post(self.api_url, headers=headers, 
                                   data=json.dumps(data), timeout=10)
            
            if response.status_code == 200:
                logger.info("âœ… LINEé€šçŸ¥é€ä¿¡å®Œäº†")
                return True
            else:
                logger.error(f"âŒ LINEé€šçŸ¥å¤±æ•—: {response.status_code}")
                logger.error(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ LINEé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return False
    
    def _format_health_message(self, report: Dict) -> str:
        """å¥åº·ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ"""
        current_bf = report.get('current_body_fat_rate', 0)
        target_bf = report.get('target_body_fat_rate', 12.0)
        progress = report.get('body_fat_progress', {})
        
        message = f"""ğŸ“Šä½“è„‚è‚ªç‡é€²æ— | {report.get('timestamp', 'N/A')}

ğŸ¯ {current_bf:.1f}% ã€GitHub Actionsã€‘

ç¾åœ¨: {current_bf:.1f}%  ç›®æ¨™: {target_bf:.1f}%
28æ—¥: {progress.get('28day_change', 0):+.1f}%  14æ—¥: {progress.get('14day_change', 0):+.1f}%  7æ—¥: {progress.get('7day_change', 0):+.1f}%

ğŸ’ªä½“çµ„æˆå¤‰åŒ–ãƒˆãƒ¬ãƒ³ãƒ‰
ä½“é‡: {report.get('body_composition', {}).get('weight', 0):.1f}kg
ç­‹è‚‰é‡: {report.get('body_composition', {}).get('muscle_mass', 0):.1f}kg
ä½“è„‚è‚ªé‡: {report.get('body_composition', {}).get('body_fat_mass', 0):.1f}kg

ğŸ”¥ã‚«ãƒ­ãƒªãƒ¼åæ”¯çŠ¶æ³
ç¾åœ¨: {report.get('calorie_balance', {}).get('current', 0):.0f}kcal
7æ—¥å¹³å‡: {report.get('calorie_balance', {}).get('7day_avg', 0):.0f}kcal

ã€GitHub Actions v1.0ã€‘å®Œå…¨ç„¡æ–™ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­âœ…"""

        return message

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¯ãƒ©ã‚¹ =====
class GitHubHealthProcessor:
    """GitHub Actionsç”¨çµ±åˆå¥åº·ç®¡ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼"""
    
    def __init__(self):
        self.env = GitHubEnvironment()
        self.converter = HAEDataConverter()
        self.integrator = CSVDataIntegrator(self.env.reports_dir)
        self.analytics = HealthAnalyticsEngine(self.env.reports_dir)
        self.notifier = LineBotNotifier()
        logger.info("ğŸš€ GitHubå¥åº·ç®¡ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–å®Œäº†")
    
    def process_new_data(self) -> bool:
        """æ–°ã—ã„HAEãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºãƒ»å‡¦ç†"""
        try:
            logger.info("ğŸ¯ ===== æ–°ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹ =====")
            
            # æ–°ã—ã„JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            new_files = self._find_new_data_files()
            if not new_files:
                logger.info("ğŸ“­ æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
                return True  # ãƒ‡ãƒ¼ã‚¿ãªã—ã¯æ­£å¸¸
            
            logger.info(f"ğŸ“ æ–°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(new_files)}å€‹")
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            latest_file = max(new_files, key=lambda x: x.stat().st_mtime)
            logger.info(f"ğŸ“„ å‡¦ç†å¯¾è±¡: {latest_file.name}")
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†
            with open(latest_file, 'r', encoding='utf-8') as f:
                hae_data = json.load(f)
            
            return self._process_hae_data_complete(hae_data)
            
        except Exception as e:
            logger.error(f"âŒ æ–°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return False
    
    def _find_new_data_files(self) -> List[Path]:
        """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        data_files = list(self.env.data_dir.glob("*.json"))
        
        # 24æ™‚é–“ä»¥å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°ã—ã„ã¨ã¿ãªã™
        cutoff_time = datetime.now() - timedelta(hours=24)
        new_files = []
        
        for file_path in data_files:
            file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
            if file_time > cutoff_time:
                new_files.append(file_path)
        
        return new_files
    
    def _process_hae_data_complete(self, hae_data: Dict) -> bool:
        """HAEãƒ‡ãƒ¼ã‚¿å®Œå…¨å‡¦ç†"""
        try:
            logger.info("ğŸ¯ ===== HAEãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†é–‹å§‹ =====")
            
            # 1. HAE â†’ CSVå¤‰æ›
            logger.info("ã€STEP 1ã€‘ HAEãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Ÿè¡Œ")
            daily_row = self.converter.convert_hae_to_daily_row(hae_data)
            if not daily_row:
                logger.error("âŒ ãƒ‡ãƒ¼ã‚¿å¤‰æ›å¤±æ•—")
                return False
            
            # 2. CSVçµ±åˆãƒ»ç§»å‹•å¹³å‡
            logger.info("ã€STEP 2ã€‘ CSVçµ±åˆãƒ»ç§»å‹•å¹³å‡å®Ÿè¡Œ")
            if not self.integrator.integrate_daily_data(daily_row):
                logger.error("âŒ CSVçµ±åˆå¤±æ•—")
                return False
            
            # 3. å¥åº·åˆ†æ
            logger.info("ã€STEP 3ã€‘ å¥åº·åˆ†æå®Ÿè¡Œ")
            report = self.analytics.analyze_health_data()
            if not report:
                logger.error("âŒ å¥åº·åˆ†æå¤±æ•—")
                return False
            
            # 4. LINEé€šçŸ¥
            logger.info("ã€STEP 4ã€‘ LINEé€šçŸ¥å®Ÿè¡Œ")
            if not self.notifier.send_health_report(report):
                logger.warning("âš ï¸ LINEé€šçŸ¥å¤±æ•—ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰")
            
            logger.info("ğŸ‰ ===== HAEãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†å®Œäº† =====")
            return True
            
        except Exception as e:
            logger.error(f"âŒ HAEãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return False
    
    def run_manual_analysis(self) -> bool:
        """æ‰‹å‹•åˆ†æå®Ÿè¡Œ"""
        try:
            logger.info("ğŸ§  ===== æ‰‹å‹•åˆ†æå®Ÿè¡Œ =====")
            
            report = self.analytics.analyze_health_data()
            if report:
                notification_success = self.notifier.send_health_report(report)
                logger.info(f"ğŸ“± LINEé€šçŸ¥: {'âœ…æˆåŠŸ' if notification_success else 'âŒå¤±æ•—'}")
                return True
            else:
                logger.error("âŒ æ‰‹å‹•åˆ†æå¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ‰‹å‹•åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return False

# ===== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ =====
def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info("ğŸ¥ ===== GitHub Actions ä½“çµ„æˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ =====")
        logger.info(f"ğŸ“… å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
        processor = GitHubHealthProcessor()
        
        # ç’°å¢ƒå¤‰æ•°ç¢ºèª
        logger.info("ğŸ” ç’°å¢ƒå¤‰æ•°ç¢ºèª:")
        logger.info(f"  LINEè¨­å®š: {'âœ…å®Œäº†' if os.environ.get('LINE_BOT_CHANNEL_ACCESS_TOKEN') and os.environ.get('LINE_USER_ID') else 'âŒä¸å®Œå…¨'}")
        logger.info(f"  OURAè¨­å®š: {'âœ…å®Œäº†' if os.environ.get('OURA_ACCESS_TOKEN') else 'âŒæœªè¨­å®š'}")
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥å‡¦ç†åˆ†å²
        event_name = processor.env.event_name
        logger.info(f"ğŸ”„ å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {event_name}")
        
        success = False
        
        if event_name == 'workflow_dispatch':
            # æ‰‹å‹•å®Ÿè¡Œ
            logger.info("ğŸ‘¤ æ‰‹å‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
            success = processor.run_manual_analysis()
        
        elif event_name == 'push':
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒƒã‚·ãƒ¥æ™‚
            logger.info("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒƒã‚·ãƒ¥ãƒ¢ãƒ¼ãƒ‰")
            success = processor.process_new_data()
        
        elif event_name == 'schedule':
            # å®šæœŸå®Ÿè¡Œ
            logger.info("â° å®šæœŸå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
            success = processor.run_manual_analysis()
        
        else:
            # ãã®ä»–ãƒ»ä¸æ˜
            logger.info("â“ ä¸æ˜ãªã‚¤ãƒ™ãƒ³ãƒˆ - æ‰‹å‹•åˆ†æå®Ÿè¡Œ")
            success = processor.run_manual_analysis()
        
        # å®Ÿè¡Œçµæœ
        if success:
            logger.info("ğŸ‰ ===== ä½“çµ„æˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†ï¼ˆæˆåŠŸï¼‰ =====")
            print("âœ… ğŸ˜€ ğ ®· ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦")  # Unicodeæ¤œè¨¼å‡ºåŠ›
        else:
            logger.error("âŒ ===== ä½“çµ„æˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†ï¼ˆå¤±æ•—ï¼‰ =====")
            sys.exit(1)
        
    except Exception as e:
        logger.error(f"âŒ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()
